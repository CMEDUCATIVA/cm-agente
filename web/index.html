<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CM-Agente Voz</title>
  <style>
    :root {
      --bg: #f6f2ed;
      --panel: #ffffff;
      --ink: #1c1c1c;
      --muted: #6b6b6b;
      --accent: #e04f2a;
      --accent-2: #2b7a78;
      --ring: rgba(224, 79, 42, 0.25);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      font-family: "IBM Plex Sans", "Segoe UI", sans-serif;
      background: radial-gradient(1200px 600px at 20% -10%, #fbe9df, transparent),
                  radial-gradient(1000px 500px at 120% 10%, #d6f0ee, transparent),
                  var(--bg);
      color: var(--ink);
    }
    .wrap {
      max-width: 860px;
      margin: 48px auto;
      padding: 0 20px;
    }
    .card {
      background: var(--panel);
      border-radius: 18px;
      padding: 28px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.08);
    }
    h1 {
      font-size: 28px;
      margin: 0 0 8px;
      letter-spacing: -0.3px;
    }
    .sub {
      color: var(--muted);
      margin: 0 0 24px;
    }
    .controls {
      display: flex;
      gap: 12px;
      flex-wrap: wrap;
      margin-bottom: 18px;
    }
    button {
      appearance: none;
      border: 0;
      background: var(--accent);
      color: #fff;
      padding: 12px 18px;
      border-radius: 12px;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.08s ease, box-shadow 0.2s ease;
      box-shadow: 0 6px 18px var(--ring);
    }
    button.secondary {
      background: #111;
    }
    button:disabled {
      opacity: 0.55;
      cursor: not-allowed;
    }
    button:active { transform: translateY(1px); }
    .status {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border-radius: 999px;
      background: #f2f2f2;
      color: var(--muted);
      font-size: 13px;
    }
    .dot {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background: #bbb;
    }
    .dot.live { background: var(--accent); box-shadow: 0 0 0 6px var(--ring); }
    .row {
      display: grid;
      grid-template-columns: 1fr;
      gap: 14px;
    }
    textarea {
      width: 100%;
      min-height: 80px;
      border-radius: 12px;
      border: 1px solid #ddd;
      padding: 12px;
      font-size: 14px;
      resize: vertical;
    }
    .panel {
      background: #fafafa;
      border: 1px dashed #e0e0e0;
      border-radius: 12px;
      padding: 12px;
      font-size: 14px;
    }
    .label { font-weight: 600; margin-bottom: 6px; }
    audio { width: 100%; margin-top: 8px; }
    .hint { font-size: 12px; color: var(--muted); }
    .log-box {
      max-height: 220px;
      overflow-y: auto;
      white-space: pre-wrap;
      font-family: "IBM Plex Mono", "SFMono-Regular", monospace;
      background: #f7f3ef;
      border-radius: 8px;
      padding: 8px;
    }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>Conversacion por Voz (Realtime)</h1>
      <p class="sub">WebSocket realtime. Habla y recibe audio en streaming. Se corta la respuesta si vuelves a hablar.</p>

      <div class="controls">
        <button id="startBtn">Hablar</button>
        <button id="stopBtn" class="secondary" disabled>Enviar</button>
        <button id="autoBtn" class="secondary">Continuo: OFF</button>
        <button id="copyStateBtn" class="secondary">Copiar Estado</button>
        <span class="status"><span id="dot" class="dot"></span><span id="statusText">Listo</span></span>
      </div>

      <div class="row">
        <div>
          <div class="label">Texto (opcional)</div>
          <textarea id="textInput" placeholder="Escribe si no quieres usar audio..."></textarea>
          <div class="hint">Si grabas audio, el texto se ignora.</div>
        </div>
        <div class="panel">
          <div class="label">Estado</div>
          <div id="log" class="log-box">—</div>
        </div>
        <div class="panel">
          <div class="label">Transcripcion</div>
          <div id="transcript">�</div>
        </div>
        <div class="panel">
          <div class="label">Respuesta</div>
          <div id="reply">�</div>
          <audio id="audio" controls></audio>
        </div>
      </div>
    </div>
  </div>

    <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const autoBtn = document.getElementById('autoBtn');
    const copyStateBtn = document.getElementById('copyStateBtn');
    const statusText = document.getElementById('statusText');
    const dot = document.getElementById('dot');
    const transcriptEl = document.getElementById('transcript');
    const replyEl = document.getElementById('reply');
    const audioEl = document.getElementById('audio');
    const textInput = document.getElementById('textInput');
    const logEl = document.getElementById('log');

    let ws;
    let audioQueue = [];
    let mediaSource;
    let sourceBuffer;
    let endOfStreamPending = false;
    const logLines = [];
    let autoMode = true;
    const threadId = (crypto && crypto.randomUUID) ? crypto.randomUUID() : `${Date.now()}-${Math.random()}`;
    let isSpeaking = false;
    let responseDone = false;
    let audioReceived = false;
    let audioBufferedBytes = 0;
    let playbackStarted = false;
    const MIN_PLAY_BYTES = 10000;
    const MIN_APPEND_BYTES = 6000;

    let captureCtx;
    let captureStream;
    let captureSource;
    let captureProcessor;
    let captureGain;
    let captureRunning = false;
    let captureRequested = false;
    const TARGET_SAMPLE_RATE = 16000;
    const PROCESSOR_SIZE = 4096;

    function setStatus(text, live=false) {
      statusText.textContent = text;
      dot.classList.toggle('live', live);
      log(`status: ${text}`);
    }

    function log(msg) {
      logLines.push(msg);
      logEl.textContent = logLines.join('\n');
      logEl.scrollTop = logEl.scrollHeight;
    }

    async function copyState() {
      const stateText = logLines.join('\n');
      if (!stateText.trim()) {
        log('estado vacio: nada para copiar');
        return;
      }
      try {
        await navigator.clipboard.writeText(stateText);
        log('estado copiado al portapapeles');
      } catch (err) {
        log('no se pudo copiar el estado');
      }
    }

    function resetAudioStream() {
      audioQueue = [];
      endOfStreamPending = false;
      responseDone = false;
      audioReceived = false;
      audioBufferedBytes = 0;
      playbackStarted = false;
      mediaSource = new MediaSource();
      audioEl.src = URL.createObjectURL(mediaSource);
      mediaSource.addEventListener('sourceopen', () => {
        sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg');
        sourceBuffer.addEventListener('updateend', appendNextChunk);
        appendNextChunk();
      }, { once: true });
    }

    function stopPlayback() {
      try {
        audioEl.pause();
        audioEl.currentTime = 0;
      } catch (_) {}
      audioQueue = [];
      endOfStreamPending = false;
      audioBufferedBytes = 0;
      playbackStarted = false;
      if (mediaSource && mediaSource.readyState === 'open') {
        try {
          mediaSource.endOfStream();
        } catch (_) {}
      }
    }

    function appendNextChunk() {
      if (!sourceBuffer || sourceBuffer.updating) return;
      if (audioQueue.length > 0) {
        let total = 0;
        let parts = [];
        while (audioQueue.length > 0 && total < MIN_APPEND_BYTES) {
          const part = audioQueue.shift();
          parts.push(part);
          total += part.length;
        }
        if (parts.length === 1) {
          sourceBuffer.appendBuffer(parts[0]);
        } else {
          const merged = new Uint8Array(total);
          let offset = 0;
          for (const part of parts) {
            merged.set(part, offset);
            offset += part.length;
          }
          sourceBuffer.appendBuffer(merged);
        }
      } else if (endOfStreamPending && mediaSource.readyState === 'open') {
        mediaSource.endOfStream();
      } else if (playbackStarted && audioEl.paused) {
        audioEl.play().catch(() => {});
      }
    }

    function pushAudioChunk(b64) {
      const binary = atob(b64);
      const bytes = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) {
        bytes[i] = binary.charCodeAt(i);
      }
      audioQueue.push(bytes);
      audioBufferedBytes += bytes.length;
      appendNextChunk();
      if (!playbackStarted && audioBufferedBytes >= MIN_PLAY_BYTES) {
        playbackStarted = true;
        audioEl.play().catch(() => {});
      }
    }

    function downsampleBuffer(buffer, inputRate, outputRate) {
      if (outputRate === inputRate) return buffer;
      const ratio = inputRate / outputRate;
      const newLength = Math.round(buffer.length / ratio);
      const result = new Float32Array(newLength);
      let offsetResult = 0;
      let offsetBuffer = 0;
      while (offsetResult < result.length) {
        const nextOffsetBuffer = Math.round((offsetResult + 1) * ratio);
        let accum = 0;
        let count = 0;
        for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
          accum += buffer[i];
          count += 1;
        }
        result[offsetResult] = count ? (accum / count) : 0;
        offsetResult += 1;
        offsetBuffer = nextOffsetBuffer;
      }
      return result;
    }

    function floatTo16BitPCM(float32Array) {
      const len = float32Array.length;
      const int16 = new Int16Array(len);
      for (let i = 0; i < len; i++) {
        let s = Math.max(-1, Math.min(1, float32Array[i]));
        int16[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
      }
      return int16;
    }

    function encodePcmToBase64(int16Array) {
      const bytes = new Uint8Array(int16Array.buffer);
      let binary = '';
      for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);
      return btoa(binary);
    }

    function sendPcmChunk(int16Array) {
      if (!ws || ws.readyState !== WebSocket.OPEN) return;
      ws.send(JSON.stringify({
        type: 'pcm_chunk',
        sample_rate: TARGET_SAMPLE_RATE,
        data: encodePcmToBase64(int16Array)
      }));
    }

    async function startCapture() {
      captureRequested = true;
      if (captureRunning) return;
      connectWs();
      try {
        captureStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
      } catch (err) {
        setStatus('Permiso de microfono denegado', false);
        return;
      }

      captureCtx = new (window.AudioContext || window.webkitAudioContext)();
      captureSource = captureCtx.createMediaStreamSource(captureStream);
      captureProcessor = captureCtx.createScriptProcessor(PROCESSOR_SIZE, 1, 1);
      captureGain = captureCtx.createGain();
      captureGain.gain.value = 0;

      captureProcessor.onaudioprocess = (event) => {
        if (!captureRunning) return;
        const input = event.inputBuffer.getChannelData(0);
        const downsampled = downsampleBuffer(input, captureCtx.sampleRate, TARGET_SAMPLE_RATE);
        const pcm16 = floatTo16BitPCM(downsampled);
        if (pcm16.length) sendPcmChunk(pcm16);
      };

      captureSource.connect(captureProcessor);
      captureProcessor.connect(captureGain);
      captureGain.connect(captureCtx.destination);

      captureRunning = true;
      setStatus('Escuchando...', true);
    }

    async function stopCapture(keepRequested = false) {
      captureRunning = false;
      if (!keepRequested) captureRequested = false;
      if (captureProcessor) {
        captureProcessor.disconnect();
        captureProcessor = null;
      }
      if (captureSource) {
        captureSource.disconnect();
        captureSource = null;
      }
      if (captureGain) {
        captureGain.disconnect();
        captureGain = null;
      }
      if (captureStream) {
        captureStream.getTracks().forEach(t => t.stop());
        captureStream = null;
      }
      if (captureCtx) {
        await captureCtx.close().catch(() => {});
        captureCtx = null;
      }
      setStatus('Listo', false);
    }

    function connectWs() {
      if (ws && (ws.readyState === WebSocket.OPEN || ws.readyState === WebSocket.CONNECTING)) {
        return;
      }
      const proto = location.protocol === 'https:' ? 'wss' : 'ws';
      ws = new WebSocket(`${proto}://${location.host}/voice/ws`);
      ws.onopen = () => {
        setStatus('Conectado', false);
        ws.send(JSON.stringify({ type: 'config', thread_id: threadId }));
        log('ws open');
        if (autoMode) startCapture();
      };
      ws.onclose = () => {
        setStatus('Desconectado', false);
        log('ws close');
      };
      ws.onerror = () => {
        setStatus('Error WS', false);
        log('ws error');
      };
      ws.onmessage = (event) => {
        if (event.data && event.data.startsWith('{"type":"audio_chunk"')) {
          log('ws message: audio_chunk');
        } else {
          log(`ws message: ${event.data.slice(0, 120)}`);
        }
        const msg = JSON.parse(event.data);
        if (msg.type === 'status') {
          setStatus(msg.value, msg.value === 'processing');
          if (msg.value === 'processing') {
            replyEl.textContent = '';
            transcriptEl.textContent = '—';
            resetAudioStream();
          }
          if (msg.value === 'done' && autoMode) {
            responseDone = true;
          }
          if (msg.value === 'interrupted') {
            stopPlayback();
          }
        } else if (msg.type === 'speech_start') {
          log('vad: speech_start');
        } else if (msg.type === 'speech_end') {
          log('vad: speech_end');
        } else if (msg.type === 'transcript') {
          transcriptEl.textContent = msg.text || '(sin transcripcion)';
        } else if (msg.type === 'text_delta') {
          replyEl.textContent += msg.text;
        } else if (msg.type === 'final_text') {
          replyEl.textContent = msg.text || replyEl.textContent;
        } else if (msg.type === 'audio_chunk') {
          isSpeaking = true;
          audioReceived = true;
          if (!mediaSource) resetAudioStream();
          pushAudioChunk(msg.data);
        } else if (msg.type === 'audio_end') {
          endOfStreamPending = true;
          appendNextChunk();
          if (!playbackStarted) {
            playbackStarted = true;
            audioEl.play().catch(() => {});
          }
        } else if (msg.type === 'error') {
          setStatus('Error', false);
          replyEl.textContent = msg.message || 'Error';
        }
      };
    }

    startBtn.addEventListener('click', startCapture);
    stopBtn.addEventListener('click', () => {
      const text = textInput.value.trim();
      if (text && ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'text', text }));
        textInput.value = '';
        return;
      }
      stopCapture();
    });
    autoBtn.addEventListener('click', () => {
      autoMode = !autoMode;
      autoBtn.textContent = autoMode ? 'Continuo: ON' : 'Continuo: OFF';
      if (autoMode) {
        startCapture();
      } else {
        stopCapture();
      }
    });
    copyStateBtn.addEventListener('click', copyState);
    audioEl.addEventListener('play', () => {
      isSpeaking = true;
      if (captureRunning) stopCapture(true);
    });
    audioEl.addEventListener('pause', () => {
      isSpeaking = false;
      if (autoMode && captureRequested && !captureRunning) startCapture();
    });
    audioEl.addEventListener('ended', () => {
      isSpeaking = false;
      if (autoMode && captureRequested && !captureRunning) startCapture();
    });
    autoBtn.textContent = autoMode ? 'Continuo: ON' : 'Continuo: OFF';
    connectWs();
  </script>
</body>
</html>
