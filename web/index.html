<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CM-Agente Voz</title>
  <style>
    :root {
      --bg: #f6f2ed;
      --panel: #ffffff;
      --ink: #1c1c1c;
      --muted: #6b6b6b;
      --accent: #e04f2a;
      --accent-2: #2b7a78;
      --ring: rgba(224, 79, 42, 0.25);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      font-family: "IBM Plex Sans", "Segoe UI", sans-serif;
      background: radial-gradient(1200px 600px at 20% -10%, #fbe9df, transparent),
                  radial-gradient(1000px 500px at 120% 10%, #d6f0ee, transparent),
                  var(--bg);
      color: var(--ink);
    }
    .wrap {
      max-width: 860px;
      margin: 48px auto;
      padding: 0 20px;
    }
    .card {
      background: var(--panel);
      border-radius: 18px;
      padding: 28px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.08);
    }
    h1 {
      font-size: 28px;
      margin: 0 0 8px;
      letter-spacing: -0.3px;
    }
    .sub {
      color: var(--muted);
      margin: 0 0 24px;
    }
    .controls {
      display: flex;
      gap: 12px;
      flex-wrap: wrap;
      margin-bottom: 18px;
    }
    button {
      appearance: none;
      border: 0;
      background: var(--accent);
      color: #fff;
      padding: 12px 18px;
      border-radius: 12px;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.08s ease, box-shadow 0.2s ease;
      box-shadow: 0 6px 18px var(--ring);
    }
    button.secondary {
      background: #111;
    }
    button:disabled {
      opacity: 0.55;
      cursor: not-allowed;
    }
    button:active { transform: translateY(1px); }
    .status {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border-radius: 999px;
      background: #f2f2f2;
      color: var(--muted);
      font-size: 13px;
    }
    .dot {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background: #bbb;
    }
    .dot.live { background: var(--accent); box-shadow: 0 0 0 6px var(--ring); }
    .row {
      display: grid;
      grid-template-columns: 1fr;
      gap: 14px;
    }
    textarea {
      width: 100%;
      min-height: 80px;
      border-radius: 12px;
      border: 1px solid #ddd;
      padding: 12px;
      font-size: 14px;
      resize: vertical;
    }
    .panel {
      background: #fafafa;
      border: 1px dashed #e0e0e0;
      border-radius: 12px;
      padding: 12px;
      font-size: 14px;
    }
    .label { font-weight: 600; margin-bottom: 6px; }
    audio { width: 100%; margin-top: 8px; }
    .hint { font-size: 12px; color: var(--muted); }
    .log-box {
      max-height: 220px;
      overflow-y: auto;
      white-space: pre-wrap;
      font-family: "IBM Plex Mono", "SFMono-Regular", monospace;
      background: #f7f3ef;
      border-radius: 8px;
      padding: 8px;
    }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>Conversacion por Voz (Realtime)</h1>
      <p class="sub">WebSocket realtime. Habla y recibe audio en streaming. Se corta la respuesta si vuelves a hablar.</p>

      <div class="controls">
        <button id="startBtn">Hablar</button>
        <button id="stopBtn" class="secondary" disabled>Enviar</button>
        <button id="autoBtn" class="secondary">Continuo: OFF</button>
        <button id="copyStateBtn" class="secondary">Copiar Estado</button>
        <span class="status"><span id="dot" class="dot"></span><span id="statusText">Listo</span></span>
      </div>

      <div class="row">
        <div>
          <div class="label">Texto (opcional)</div>
          <textarea id="textInput" placeholder="Escribe si no quieres usar audio..."></textarea>
          <div class="hint">Si grabas audio, el texto se ignora.</div>
        </div>
        <div class="panel">
          <div class="label">Estado</div>
          <div id="log" class="log-box">—</div>
        </div>
        <div class="panel">
          <div class="label">Transcripcion</div>
          <div id="transcript">�</div>
        </div>
        <div class="panel">
          <div class="label">Respuesta</div>
          <div id="reply">�</div>
          <audio id="audio" controls></audio>
        </div>
      </div>
    </div>
  </div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const autoBtn = document.getElementById('autoBtn');
    const copyStateBtn = document.getElementById('copyStateBtn');
    const statusText = document.getElementById('statusText');
    const dot = document.getElementById('dot');
    const transcriptEl = document.getElementById('transcript');
    const replyEl = document.getElementById('reply');
    const audioEl = document.getElementById('audio');
    const textInput = document.getElementById('textInput');
    const logEl = document.getElementById('log');

    let ws;
    let mediaRecorder;
    let stream;
    let isRecording = false;
    let audioQueue = [];
    let chunks = [];
    let mediaSource;
    let sourceBuffer;
    let endOfStreamPending = false;
    const logLines = [];
    let autoMode = false;
    const threadId = (crypto && crypto.randomUUID) ? crypto.randomUUID() : `${Date.now()}-${Math.random()}`;
    let audioCtx;
    let analyser;
    let vadRunning = false;
    let speechSeen = false;
    let lastVoiceTs = 0;
    let bargeStream;
    let bargeCtx;
    let bargeAnalyser;
    let bargeRunning = false;
    let bargeHits = 0;
    const VAD_THRESHOLD = 0.02;
    const VAD_SILENCE_MS = 900;
    const VAD_MIN_VOICE_RATIO = 0.18;
    const VAD_MIN_ENERGY_DB = -55;
    const VAD_BARGE_HITS = 2;
    let processing = false;
    let isSpeaking = false;
    let audioEnded = true;
    let responseDone = false;
    let audioReceived = false;
    let audioBufferedBytes = 0;
    let playbackStarted = false;
    const MIN_PLAY_BYTES = 10000;
    const MIN_APPEND_BYTES = 6000;
    const MIN_RECORD_BYTES = 6000;
    let recordedBytes = 0;

    function setStatus(text, live=false) {
      statusText.textContent = text;
      dot.classList.toggle('live', live);
      log(`status: ${text}`);
    }

    function log(msg) {
      logLines.push(msg);
      logEl.textContent = logLines.join('\n');
      logEl.scrollTop = logEl.scrollHeight;
    }

    async function copyState() {
      const stateText = logLines.join('\n');
      if (!stateText.trim()) {
        log('estado vacio: nada para copiar');
        return;
      }
      try {
        await navigator.clipboard.writeText(stateText);
        log('estado copiado al portapapeles');
      } catch (err) {
        log('no se pudo copiar el estado');
      }
    }

    function resetAudioStream() {
      audioQueue = [];
      endOfStreamPending = false;
      audioEnded = false;
      responseDone = false;
      audioReceived = false;
      audioBufferedBytes = 0;
      playbackStarted = false;
      mediaSource = new MediaSource();
      audioEl.src = URL.createObjectURL(mediaSource);
      mediaSource.addEventListener('sourceopen', () => {
        sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg');
        sourceBuffer.addEventListener('updateend', appendNextChunk);
        appendNextChunk();
      }, { once: true });
    }

    async function startBargeInMonitor() {
      if (bargeRunning || isRecording) return;
      try {
        bargeStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        log('barge-in: permiso de microfono denegado');
        return;
      }
      bargeCtx = new (window.AudioContext || window.webkitAudioContext)();
      bargeAnalyser = bargeCtx.createAnalyser();
      bargeAnalyser.fftSize = 2048;
      const src = bargeCtx.createMediaStreamSource(bargeStream);
      src.connect(bargeAnalyser);
      bargeRunning = true;
      bargeHits = 0;
      runBargeIn();
    }

    function stopBargeInMonitor() {
      bargeRunning = false;
      bargeHits = 0;
      if (bargeStream) {
        bargeStream.getTracks().forEach(t => t.stop());
        bargeStream = null;
      }
      if (bargeCtx) {
        bargeCtx.close().catch(() => {});
        bargeCtx = null;
        bargeAnalyser = null;
      }
    }

    function detectVoice(currentAnalyser, currentCtx) {
      if (!currentAnalyser || !currentCtx) return { rms: 0, hasVoice: false };
      const data = new Uint8Array(currentAnalyser.fftSize);
      currentAnalyser.getByteTimeDomainData(data);
      let sum = 0;
      for (let i = 0; i < data.length; i++) {
        const v = (data[i] - 128) / 128;
        sum += v * v;
      }
      const rms = Math.sqrt(sum / data.length);
      const freqData = new Float32Array(currentAnalyser.frequencyBinCount);
      currentAnalyser.getFloatFrequencyData(freqData);
      const nyquist = currentCtx.sampleRate / 2;
      const binHz = nyquist / freqData.length;
      let voiceEnergy = 0;
      let totalEnergy = 0;
      for (let i = 0; i < freqData.length; i++) {
        const db = freqData[i];
        if (db < VAD_MIN_ENERGY_DB) continue;
        const hz = i * binHz;
        const linear = Math.pow(10, db / 20);
        totalEnergy += linear;
        if (hz >= 85 && hz <= 3000) {
          voiceEnergy += linear;
        }
      }
      const ratio = totalEnergy > 0 ? voiceEnergy / totalEnergy : 0;
      return { rms, hasVoice: ratio >= VAD_MIN_VOICE_RATIO };
    }

    function runBargeIn() {
      if (!bargeRunning || !bargeAnalyser || !bargeCtx) return;
      const { rms, hasVoice } = detectVoice(bargeAnalyser, bargeCtx);
      if (rms > VAD_THRESHOLD && hasVoice) {
        bargeHits += 1;
      } else {
        bargeHits = 0;
      }
      if (bargeHits >= VAD_BARGE_HITS) {
        bargeHits = 0;
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: 'interrupt' }));
        }
        stopPlayback();
        if (!isRecording) {
          startRecording(true);
        }
        return;
      }
      requestAnimationFrame(runBargeIn);
    }

    function stopPlayback() {
      try {
        audioEl.pause();
        audioEl.currentTime = 0;
      } catch (_) {}
      audioQueue = [];
      endOfStreamPending = false;
      audioBufferedBytes = 0;
      playbackStarted = false;
      if (mediaSource && mediaSource.readyState === 'open') {
        try {
          mediaSource.endOfStream();
        } catch (_) {}
      }
      stopBargeInMonitor();
    }

    function appendNextChunk() {
      if (!sourceBuffer || sourceBuffer.updating) return;
      if (audioQueue.length > 0) {
        let total = 0;
        let parts = [];
        while (audioQueue.length > 0 && total < MIN_APPEND_BYTES) {
          const part = audioQueue.shift();
          parts.push(part);
          total += part.length;
        }
        if (parts.length === 1) {
          sourceBuffer.appendBuffer(parts[0]);
        } else {
          const merged = new Uint8Array(total);
          let offset = 0;
          for (const part of parts) {
            merged.set(part, offset);
            offset += part.length;
          }
          sourceBuffer.appendBuffer(merged);
        }
      } else if (endOfStreamPending && mediaSource.readyState === 'open') {
        mediaSource.endOfStream();
      } else if (playbackStarted && audioEl.paused) {
        audioEl.play().catch(() => {});
      }
    }

    function pushAudioChunk(b64) {
      const binary = atob(b64);
      const bytes = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) {
        bytes[i] = binary.charCodeAt(i);
      }
      audioQueue.push(bytes);
      audioBufferedBytes += bytes.length;
      appendNextChunk();
      if (!playbackStarted && audioBufferedBytes >= MIN_PLAY_BYTES) {
        playbackStarted = true;
        audioEl.play().catch(() => {});
      }
    }

    function connectWs() {
      if (ws && (ws.readyState === WebSocket.OPEN || ws.readyState === WebSocket.CONNECTING)) {
        return;
      }
      const proto = location.protocol === 'https:' ? 'wss' : 'ws';
      ws = new WebSocket(`${proto}://${location.host}/voice/ws`);
      ws.onopen = () => {
        setStatus('Conectado', false);
        ws.send(JSON.stringify({ type: 'config', thread_id: threadId }));
        log('ws open');
      };
      ws.onclose = () => {
        setStatus('Desconectado', false);
        log('ws close');
      };
      ws.onerror = () => {
        setStatus('Error WS', false);
        log('ws error');
      };
      ws.onmessage = (event) => {
        // Avoid flooding the UI log with large audio payloads
        if (event.data && event.data.startsWith('{"type":"audio_chunk"')) {
          log('ws message: audio_chunk');
        } else {
          log(`ws message: ${event.data.slice(0, 120)}`);
        }
        const msg = JSON.parse(event.data);
        if (msg.type === 'status') {
          setStatus(msg.value, msg.value === 'processing');
          if (msg.value === 'processing') processing = true;
          if (msg.value === 'done' || msg.value === 'error' || msg.value === 'interrupted') {
            processing = false;
          }
          if (msg.value === 'done' && autoMode) {
            responseDone = true;
            if (!audioReceived && !isRecording) {
              startRecording(true);
            }
          }
          if (msg.value === 'interrupted') {
            stopPlayback();
            if (autoMode && !isRecording) {
              startRecording(true);
            }
          }
        } else if (msg.type === 'transcript') {
          transcriptEl.textContent = msg.text || '(sin transcripcion)';
        } else if (msg.type === 'text_delta') {
          replyEl.textContent += msg.text;
        } else if (msg.type === 'final_text') {
          replyEl.textContent = msg.text || replyEl.textContent;
        } else if (msg.type === 'audio_chunk') {
          isSpeaking = true;
          audioReceived = true;
          audioEnded = false;
          if (!mediaSource) resetAudioStream();
          pushAudioChunk(msg.data);
        } else if (msg.type === 'audio_end') {
          endOfStreamPending = true;
          appendNextChunk();
          if (!playbackStarted) {
            playbackStarted = true;
            audioEl.play().catch(() => {});
          }
        } else if (msg.type === 'error') {
          setStatus('Error', false);
          replyEl.textContent = msg.message || 'Error';
        }
      };
    }

    async function startRecording(auto = false) {
      connectWs();
      replyEl.textContent = '';
      transcriptEl.textContent = '—';
      resetAudioStream();
      stopBargeInMonitor();
      if (
        !auto &&
        ws &&
        ws.readyState === WebSocket.OPEN &&
        (processing || isSpeaking || !audioEnded)
      ) {
        ws.send(JSON.stringify({ type: 'interrupt' }));
        stopPlayback();
      }

      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        setStatus('Permiso de microfono denegado', false);
        return;
      }

      // VAD setup
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const src = audioCtx.createMediaStreamSource(stream);
      src.connect(analyser);
      speechSeen = false;
      lastVoiceTs = Date.now();
      vadRunning = true;
      runVad();

      chunks = [];
      recordedBytes = 0;
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) {
          chunks.push(e.data);
          recordedBytes += e.data.size;
        }
      };
      mediaRecorder.onstop = () => {
        if (ws && ws.readyState === WebSocket.OPEN) {
          if (recordedBytes < MIN_RECORD_BYTES) {
            log(`audio too short (${recordedBytes} bytes), retry`);
            if (autoMode) {
              setTimeout(() => {
                if (!isRecording) startRecording(true);
              }, 300);
            }
            return;
          }
          if (chunks.length > 0) {
            const blob = new Blob(chunks, { type: 'audio/webm;codecs=opus' });
            blob.arrayBuffer().then((buf) => {
              const bytes = new Uint8Array(buf);
              let binary = '';
              for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);
              ws.send(JSON.stringify({ type: 'audio', data: btoa(binary), mime: blob.type }));
              ws.send(JSON.stringify({ type: 'end' }));
            });
          } else if (textInput.value.trim()) {
            ws.send(JSON.stringify({ type: 'text', text: textInput.value.trim() }));
            textInput.value = '';
          } else {
            setStatus('No hay audio ni texto', false);
          }
        }
      };
      mediaRecorder.start();
      isRecording = true;
      setStatus('Grabando...', true);
      startBtn.disabled = true;
      stopBtn.disabled = false;
    }

    function runVad() {
      if (!vadRunning || !analyser) return;
      const { rms, hasVoice } = detectVoice(analyser, audioCtx);
      const now = Date.now();
      if (rms > VAD_THRESHOLD && hasVoice) {
        speechSeen = true;
        lastVoiceTs = now;
      }
      if (speechSeen && now - lastVoiceTs > VAD_SILENCE_MS) {
        stopRecording();
        return;
      }
      requestAnimationFrame(runVad);
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
      }
      vadRunning = false;
      if (audioCtx) {
        audioCtx.close().catch(() => {});
        audioCtx = null;
      }
      isRecording = false;
      startBtn.disabled = false;
      stopBtn.disabled = true;
      setStatus('Procesando...', false);

      // Envio ocurre en onstop para asegurar que MediaRecorder ya genero datos
    }

    startBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);
    autoBtn.addEventListener('click', () => {
      autoMode = !autoMode;
      autoBtn.textContent = autoMode ? 'Continuo: ON' : 'Continuo: OFF';
      if (autoMode && !isRecording) startRecording();
    });
    copyStateBtn.addEventListener('click', copyState);
    audioEl.addEventListener('play', () => {
      isSpeaking = true;
      audioEnded = false;
      startBargeInMonitor();
    });
    audioEl.addEventListener('pause', () => {
      stopBargeInMonitor();
    });
    audioEl.addEventListener('ended', () => {
      isSpeaking = false;
      audioEnded = true;
      stopBargeInMonitor();
      if (autoMode && responseDone && !isRecording) startRecording(true);
    });
    connectWs();
  </script>
</body>
</html>
