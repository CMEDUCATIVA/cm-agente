<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CM-Agente Voz</title>
  <style>
    :root {
      --bg: #f6f2ed;
      --panel: #ffffff;
      --ink: #1c1c1c;
      --muted: #6b6b6b;
      --accent: #e04f2a;
      --accent-2: #2b7a78;
      --ring: rgba(224, 79, 42, 0.25);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      font-family: "IBM Plex Sans", "Segoe UI", sans-serif;
      background: radial-gradient(1200px 600px at 20% -10%, #fbe9df, transparent),
                  radial-gradient(1000px 500px at 120% 10%, #d6f0ee, transparent),
                  var(--bg);
      color: var(--ink);
    }
    .wrap {
      max-width: 860px;
      margin: 48px auto;
      padding: 0 20px;
    }
    .card {
      background: var(--panel);
      border-radius: 18px;
      padding: 28px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.08);
    }
    h1 {
      font-size: 28px;
      margin: 0 0 8px;
      letter-spacing: -0.3px;
    }
    .sub {
      color: var(--muted);
      margin: 0 0 24px;
    }
    .controls {
      display: flex;
      gap: 12px;
      flex-wrap: wrap;
      margin-bottom: 18px;
    }
    button {
      appearance: none;
      border: 0;
      background: var(--accent);
      color: #fff;
      padding: 12px 18px;
      border-radius: 12px;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.08s ease, box-shadow 0.2s ease;
      box-shadow: 0 6px 18px var(--ring);
    }
    button.secondary {
      background: #111;
    }
    button:disabled {
      opacity: 0.55;
      cursor: not-allowed;
    }
    button:active { transform: translateY(1px); }
    .status {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border-radius: 999px;
      background: #f2f2f2;
      color: var(--muted);
      font-size: 13px;
    }
    .dot {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background: #bbb;
    }
    .dot.live { background: var(--accent); box-shadow: 0 0 0 6px var(--ring); }
    .row {
      display: grid;
      grid-template-columns: 1fr;
      gap: 14px;
    }
    textarea {
      width: 100%;
      min-height: 80px;
      border-radius: 12px;
      border: 1px solid #ddd;
      padding: 12px;
      font-size: 14px;
      resize: vertical;
    }
    .panel {
      background: #fafafa;
      border: 1px dashed #e0e0e0;
      border-radius: 12px;
      padding: 12px;
      font-size: 14px;
    }
    .label { font-weight: 600; margin-bottom: 6px; }
    audio { width: 100%; margin-top: 8px; }
    .hint { font-size: 12px; color: var(--muted); }
    .log-box {
      max-height: 220px;
      overflow-y: auto;
      white-space: pre-wrap;
      font-family: "IBM Plex Mono", "SFMono-Regular", monospace;
      background: #f7f3ef;
      border-radius: 8px;
      padding: 8px;
    }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>Conversacion por Voz (Realtime)</h1>
      <p class="sub">WebSocket realtime. Habla y recibe audio en streaming. Se corta la respuesta si vuelves a hablar.</p>

      <div class="controls">
        <button id="startBtn">Hablar</button>
        <button id="stopBtn" class="secondary" disabled>Enviar</button>
        <button id="autoBtn" class="secondary">Continuo: OFF</button>
        <span class="status"><span id="dot" class="dot"></span><span id="statusText">Listo</span></span>
      </div>

      <div class="row">
        <div>
          <div class="label">Texto (opcional)</div>
          <textarea id="textInput" placeholder="Escribe si no quieres usar audio..."></textarea>
          <div class="hint">Si grabas audio, el texto se ignora.</div>
        </div>
        <div class="panel">
          <div class="label">Estado</div>
          <div id="log" class="log-box">—</div>
        </div>
        <div class="panel">
          <div class="label">Transcripcion</div>
          <div id="transcript">�</div>
        </div>
        <div class="panel">
          <div class="label">Respuesta</div>
          <div id="reply">�</div>
          <audio id="audio" controls></audio>
        </div>
      </div>
    </div>
  </div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const autoBtn = document.getElementById('autoBtn');
    const statusText = document.getElementById('statusText');
    const dot = document.getElementById('dot');
    const transcriptEl = document.getElementById('transcript');
    const replyEl = document.getElementById('reply');
    const audioEl = document.getElementById('audio');
    const textInput = document.getElementById('textInput');
    const logEl = document.getElementById('log');

    let ws;
    let mediaRecorder;
    let stream;
    let isRecording = false;
    let audioQueue = [];
    let chunks = [];
    let mediaSource;
    let sourceBuffer;
    let endOfStreamPending = false;
    const logLines = [];
    let autoMode = false;
    const threadId = (crypto && crypto.randomUUID) ? crypto.randomUUID() : `${Date.now()}-${Math.random()}`;
    let audioCtx;
    let analyser;
    let vadRunning = false;
    let speechSeen = false;
    let lastVoiceTs = 0;
    const VAD_THRESHOLD = 0.02;
    const VAD_SILENCE_MS = 900;
    let processing = false;
    let isSpeaking = false;

    function setStatus(text, live=false) {
      statusText.textContent = text;
      dot.classList.toggle('live', live);
      log(`status: ${text}`);
    }

    function log(msg) {
      logLines.push(msg);
      logEl.textContent = logLines.join('\n');
      logEl.scrollTop = logEl.scrollHeight;
    }

    function resetAudioStream() {
      audioQueue = [];
      endOfStreamPending = false;
      mediaSource = new MediaSource();
      audioEl.src = URL.createObjectURL(mediaSource);
      mediaSource.addEventListener('sourceopen', () => {
        sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg');
        sourceBuffer.addEventListener('updateend', appendNextChunk);
        appendNextChunk();
      }, { once: true });
    }

    function appendNextChunk() {
      if (!sourceBuffer || sourceBuffer.updating) return;
      if (audioQueue.length > 0) {
        sourceBuffer.appendBuffer(audioQueue.shift());
      } else if (endOfStreamPending && mediaSource.readyState === 'open') {
        mediaSource.endOfStream();
      }
    }

    function pushAudioChunk(b64) {
      const binary = atob(b64);
      const bytes = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) {
        bytes[i] = binary.charCodeAt(i);
      }
      audioQueue.push(bytes);
      appendNextChunk();
    }

    function connectWs() {
      if (ws && (ws.readyState === WebSocket.OPEN || ws.readyState === WebSocket.CONNECTING)) {
        return;
      }
      const proto = location.protocol === 'https:' ? 'wss' : 'ws';
      ws = new WebSocket(`${proto}://${location.host}/voice/ws`);
      ws.onopen = () => {
        setStatus('Conectado', false);
        ws.send(JSON.stringify({ type: 'config', thread_id: threadId }));
        log('ws open');
      };
      ws.onclose = () => {
        setStatus('Desconectado', false);
        log('ws close');
      };
      ws.onerror = () => {
        setStatus('Error WS', false);
        log('ws error');
      };
      ws.onmessage = (event) => {
        log(`ws message: ${event.data.slice(0, 120)}`);
        const msg = JSON.parse(event.data);
        if (msg.type === 'status') {
          setStatus(msg.value, msg.value === 'processing');
          if (msg.value === 'processing') processing = true;
          if (msg.value === 'done' || msg.value === 'error') processing = false;
          if (msg.value === 'done' && autoMode) {
            setTimeout(() => {
              if (!isRecording && !isSpeaking) startRecording(true);
            }, 300);
          }
        } else if (msg.type === 'transcript') {
          transcriptEl.textContent = msg.text || '(sin transcripcion)';
        } else if (msg.type === 'text_delta') {
          replyEl.textContent += msg.text;
        } else if (msg.type === 'final_text') {
          replyEl.textContent = msg.text || replyEl.textContent;
        } else if (msg.type === 'audio_chunk') {
          isSpeaking = true;
          if (!mediaSource) resetAudioStream();
          pushAudioChunk(msg.data);
          audioEl.play().catch(() => {});
        } else if (msg.type === 'audio_end') {
          isSpeaking = false;
          endOfStreamPending = true;
          appendNextChunk();
        } else if (msg.type === 'error') {
          setStatus('Error', false);
          replyEl.textContent = msg.message || 'Error';
        }
      };
    }

    async function startRecording(auto = false) {
      connectWs();
      replyEl.textContent = '';
      transcriptEl.textContent = '—';
      resetAudioStream();
      if (!auto && (processing || isSpeaking) && ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'interrupt' }));
      }

      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        setStatus('Permiso de microfono denegado', false);
        return;
      }

      // VAD setup
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const src = audioCtx.createMediaStreamSource(stream);
      src.connect(analyser);
      speechSeen = false;
      lastVoiceTs = Date.now();
      vadRunning = true;
      runVad();

      chunks = [];
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) chunks.push(e.data);
      };
      mediaRecorder.onstop = () => {
        if (ws && ws.readyState === WebSocket.OPEN) {
          if (chunks.length > 0) {
            const blob = new Blob(chunks, { type: 'audio/webm;codecs=opus' });
            blob.arrayBuffer().then((buf) => {
              const bytes = new Uint8Array(buf);
              let binary = '';
              for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);
              ws.send(JSON.stringify({ type: 'audio', data: btoa(binary), mime: blob.type }));
              ws.send(JSON.stringify({ type: 'end' }));
            });
          } else if (textInput.value.trim()) {
            ws.send(JSON.stringify({ type: 'text', text: textInput.value.trim() }));
            textInput.value = '';
          } else {
            setStatus('No hay audio ni texto', false);
          }
        }
      };
      mediaRecorder.start();
      isRecording = true;
      setStatus('Grabando...', true);
      startBtn.disabled = true;
      stopBtn.disabled = false;
    }

    function runVad() {
      if (!vadRunning || !analyser) return;
      const data = new Uint8Array(analyser.fftSize);
      analyser.getByteTimeDomainData(data);
      let sum = 0;
      for (let i = 0; i < data.length; i++) {
        const v = (data[i] - 128) / 128;
        sum += v * v;
      }
      const rms = Math.sqrt(sum / data.length);
      const now = Date.now();
      if (rms > VAD_THRESHOLD) {
        speechSeen = true;
        lastVoiceTs = now;
      }
      if (speechSeen && now - lastVoiceTs > VAD_SILENCE_MS) {
        stopRecording();
        return;
      }
      requestAnimationFrame(runVad);
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
      }
      vadRunning = false;
      if (audioCtx) {
        audioCtx.close().catch(() => {});
        audioCtx = null;
      }
      isRecording = false;
      startBtn.disabled = false;
      stopBtn.disabled = true;
      setStatus('Procesando...', false);

      // Envio ocurre en onstop para asegurar que MediaRecorder ya genero datos
    }

    startBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);
    autoBtn.addEventListener('click', () => {
      autoMode = !autoMode;
      autoBtn.textContent = autoMode ? 'Continuo: ON' : 'Continuo: OFF';
      if (autoMode && !isRecording) startRecording();
    });
    connectWs();
  </script>
</body>
</html>
